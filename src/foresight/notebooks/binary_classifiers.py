# -*- coding: utf-8 -*-
"""binary_classifiers.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FCx7D9jhUVRpPqYO1CPPGfSihyhNmrql

This notebook uses traditional machine learning models for binary classification on mean embeddings. It skips the fine-tuning details (parameter search) and some of the lowest performing models that were abandoned.
"""

!curl ipinfo.io

gcp_project = 'foresight-375620'
gcp_bucket = 'frsght'

import google.auth
from google.colab import auth

# authenticate with gcp
auth.authenticate_user()
credentials, project_id = google.auth.default()

!gcloud config set project $gcp_project
!echo "deb http://packages.cloud.google.com/apt gcsfuse-bionic main" > /etc/apt/sources.list.d/gcsfuse.list
!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
!apt -qq update
!apt -qq install gcsfuse=0.41.12

# create colab instance directory
!mkdir -p $gcp_bucket
# mount gcp bucket to colab instance directory.
# at /content/gcp_bucket
!gcsfuse  --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $gcp_bucket $gcp_bucket
!gcsfuse  --implicit-dirs  --stat-cache-ttl 12h --type-cache-ttl 12h --stat-cache-capacity 65536 --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $gcp_bucket $gcp_bucket

!pip install gcsfs

import pandas as pd
import numpy as np
import xgboost as xgb

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, \
    confusion_matrix, precision_score, recall_score, balanced_accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

from imblearn.over_sampling import RandomOverSampler

"""## Load and prepare the data

Data preprocessing steps:
- Split into train and validation (test will be loaded later for predictions only)
- One hot encode the country information ('fips')
- Upsample to balance the classes
- Reduce dimensionality
"""

df = pd.read_csv("/content/frsght/datasets/spike_monthly_emb_means_train.csv")
len(df)

emb_cols = [col for col in df.columns if col.startswith('docembed')]

train = df[df['target_window'] < '2022-10']
val = df[df['target_window'] >= '2022-10']
print(f"Got {len(train)} training and {len(val)} validation samples.")

one_hot_encoded_train = pd.get_dummies(train, columns=['fips'])
one_hot_encoded_val = pd.get_dummies(val, columns=['fips'])
# We need to have the same features in train and test set.
one_hot_encoded_val.drop(columns=list(set(one_hot_encoded_val.columns) - set(one_hot_encoded_train.columns)), inplace=True)
one_hot_encoded_train.drop(columns=list(set(one_hot_encoded_train.columns) - set(one_hot_encoded_val.columns)), inplace=True)

feature_cols = emb_cols + [col for col in one_hot_encoded_train if col.startswith('fips')]

X_train = one_hot_encoded_train[feature_cols]
y_train = one_hot_encoded_train['lagged_spike']
X_val = one_hot_encoded_val[feature_cols]
y_val = one_hot_encoded_val['lagged_spike']

# Upsample since we have imbalance
ros = RandomOverSampler(random_state=82)
X_train, y_train = ros.fit_resample(X_train, y_train)

scaler = StandardScaler(copy=True, with_mean=True)
train_scaled = scaler.fit_transform(X_train)
val_scaled = scaler.transform(X_val)

pca = PCA(n_components=0.8)
train_proj = pca.fit_transform(train_scaled)
val_proj = pca.transform(val_scaled)

n = train_proj.shape[1]
print(f'Reduced to {n} components')
train_pca = pd.DataFrame(train_proj, columns = [f'dimension{i}' for i in range(1, n+1)])
val_pca = pd.DataFrame(val_proj, columns = [f'dimension{i}' for i in range(1, n+1)])

train_scaled = train_pca.values
val_scaled = val_pca.values

"""## Train and validate individual models

#### XGBoost
"""

xgb_clf = xgb.XGBClassifier(learning_rate=0.01, n_estimators=200)
xgb_clf.fit(train_scaled, y_train)
# binary predictions for scoring and probabilities for further stacking
predictions_xgb = xgb_clf.predict(val_scaled)
probs_xgb = xgb_clf.predict_proba(val_scaled)
print('Accuracy: ', accuracy_score(y_val, predictions_xgb))
print('Balanced accuracy: ', balanced_accuracy_score(y_val, predictions_xgb))
print('F1 score: ', f1_score(y_val, predictions_xgb))
print('ROC AUC: ', roc_auc_score(y_val, predictions_xgb))
print('Precision: ', precision_score(y_val, predictions_xgb))
print('Recall: ', recall_score(y_val, predictions_xgb))
print(confusion_matrix(y_val, predictions_xgb))

"""#### K Nearest Neighbors"""

knn_clf = KNeighborsClassifier(n_neighbors = 21)
knn_clf.fit(train_scaled, y_train)
# binary predictions for scoring and probabilities for further stacking
predictions_knn = knn_clf.predict(val_scaled)
probs_knn = knn_clf.predict_proba(val_scaled)
print('Accuracy: ', accuracy_score(y_val, predictions_knn))
print('Balanced accuracy: ', balanced_accuracy_score(y_val, predictions_knn))
print('F1 score: ', f1_score(y_val, predictions_knn))
print('ROC AUC: ', roc_auc_score(y_val, predictions_knn))
print('Precision: ', precision_score(y_val, predictions_knn))
print('Recall: ', recall_score(y_val, predictions_knn))
print(confusion_matrix(y_val, predictions_knn))

"""## Average model results"""

average_probs = np.mean(np.array([probs_xgb, probs_knn]), axis=0)
average_preds = [np.argmax(prob) for prob in average_probs]

print('Accuracy: ', accuracy_score(y_val, average_preds))
print('Balanced accuracy: ', balanced_accuracy_score(y_val, average_preds))
print('F1 score: ', f1_score(y_val, average_preds))
print('ROC AUC: ', roc_auc_score(y_val, average_preds))
print('Precision: ', precision_score(y_val, average_preds))
print('Recall: ', recall_score(y_val, average_preds))
print(confusion_matrix(y_val, average_preds))

"""## Making a sklearn like interface combined model"""

class CombinedClassifier():
    def __init__(self):
        self.xgb_clf = xgb.XGBClassifier(learning_rate=0.01, n_estimators=200)
        self.knn_clf = KNeighborsClassifier(n_neighbors = 21)

    def fit(self, X, y):
        self.xgb_clf.fit(X, y)
        self.knn_clf.fit(X, y)
    
    def predict_proba(self, X):
        probs_xgb = self.xgb_clf.predict_proba(X)
        probs_knn = self.knn_clf.predict_proba(X)
        average_probs = np.mean(np.array([probs_xgb, probs_knn]), axis=0)
        return average_probs

    def predict(self, X):
        probs = self.predict_proba(X)
        return [np.argmax(prob) for prob in probs]

"""## Retraining on full train and predicting on test data"""

train = pd.read_csv("/content/frsght/datasets/spike_monthly_emb_means_train.csv")
test = pd.read_csv("/content/frsght/datasets/spike_monthly_emb_means_test.csv")

emb_cols = [col for col in train.columns if col.startswith('docembed')]

print(f"Got {len(train)} training and {len(test)} test samples.")

one_hot_encoded_train = pd.get_dummies(train, columns=['fips'])
one_hot_encoded_test = pd.get_dummies(test, columns=['fips'])
# We need to have the same features in train and test set.
one_hot_encoded_test.drop(columns=list(set(one_hot_encoded_test.columns) - set(one_hot_encoded_train.columns)), inplace=True)
one_hot_encoded_train.drop(columns=list(set(one_hot_encoded_train.columns) - set(one_hot_encoded_test.columns)), inplace=True)

feature_cols = emb_cols + [col for col in one_hot_encoded_train if col.startswith('fips')]
X_train = one_hot_encoded_train[feature_cols]
y_train = one_hot_encoded_train['lagged_spike']
X_test = one_hot_encoded_test[feature_cols]
y_test = one_hot_encoded_test['lagged_spike']

# Upsample since we have imbalance
ros = RandomOverSampler(random_state=82)
X_train, y_train = ros.fit_resample(X_train, y_train)

scaler = StandardScaler(copy=True, with_mean=True)
train_scaled = scaler.fit_transform(X_train)
test_scaled = scaler.transform(X_test)

pca = PCA(n_components=0.8)
train_proj = pca.fit_transform(train_scaled)
test_proj = pca.transform(test_scaled)

n = train_proj.shape[1]
print(f'Reduced to {n} components')
train_pca = pd.DataFrame(train_proj, columns = [f'dimension{i}' for i in range(1, n+1)])
test_pca = pd.DataFrame(test_proj, columns = [f'dimension{i}' for i in range(1, n+1)])

train_scaled = train_pca.values
test_scaled = test_pca.values

model = CombinedClassifier()
model.fit(train_scaled, y_train)
test_predictions = model.predict(test_scaled)
test_probs = model.predict_proba(test_scaled)
# Only store probability of 1
cls_probs = [prob[1] for prob in test_probs]

to_write = pd.DataFrame()
to_write['embedding_window'] = test['window']
to_write['target_window'] = test['target_window']
to_write['lagged_spike'] = test['lagged_spike']
to_write['prediction'] = test_predictions
to_write['probabilities'] = cls_probs

to_write.head()

to_write.to_csv("/content/frsght/model_predictions/diana_preds.csv")

